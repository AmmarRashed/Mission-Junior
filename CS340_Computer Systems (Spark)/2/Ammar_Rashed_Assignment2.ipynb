{"metadata": {"language_info": {"codemirror_mode": {"name": "ipython", "version": 2}, "file_extension": ".py", "version": "2.7.11", "name": "python", "pygments_lexer": "ipython2", "mimetype": "text/x-python", "nbconvert_exporter": "python"}, "kernelspec": {"language": "python", "display_name": "Python 2 with Spark 1.6", "name": "python2"}}, "nbformat_minor": 0, "cells": [{"metadata": {"collapsed": true}, "cell_type": "markdown", "source": "<h1 align=\"center\">CS340 - Assignment 2</h1>\n<h3 align=\"center\">Due Date: 18 April 2017</h3>\n<br>\n<p style=\"text-indent: 40px\">In this project we are going to work on movielens 20m dataset with <b>PySpark Dataframes</b>. \nThe dataset is included in the assignment folder. You should unzip it and upload each file to the ibm's datascience tool.\n</p>\n\nIn order to understand the data in each csv file, you should read README.txt file inside the folder.\n\n##\u00a0Reliable Users\n\n<p style=\"text-indent: 40px\">For the first part of this assignment you should find out the top 1000 reliable users. In order to do that you would need tags' relevance score from genome-scores.csv file. Assuming the relevance scores of movies' tags in genome-scores.csv are correct, we can find out if a user's tag to a particular movie is relevant or not. If we get the total of those relevance scores for each user then we can rank the them according to this criteria.</p>\n\n<p style=\"text-indent: 40px\">One caveat is that relevance scores are between 0 and 1. We want to scale it between -1 and 1 and also we want to punish more if the issued tag is not relevant. First multiply relevance with 20 and then substract 12 so relevance score range will be between -12 and 8 and then apply hyperbolic tangent. That way relevance's range will be between -1 and 1.</p>\n\n<p style=\"text-indent: 40px\"> Note: You should use PySpark's <b>tanh</b> function. Also use caching appropriately in order to be able to get the results in a reasonable time.</p>\n<p style=\"text-indent: 40px\"> Caution: Do not use RDDs. Every operation should be done on the executors not in the driver machine.</p>\n<p style=\"text-indent: 40px\">Important: Do not discuss the solution with your friends. <b>Plagiarism</b> will not be tolerated and issue will be referred to the <b>disciplinary committee</b>.</p>\n\n<div>\n    <img src=\"http://image.prntscr.com/image/1f91352835964c31b04be03da7d53581.jpg\" width=500>\n\n    <center><strong>Figure 1: Tanh function.</strong></center>\n</div>"}, {"execution_count": 1, "metadata": {"collapsed": false}, "source": "\nfrom pyspark.sql import SQLContext\nfrom pyspark.sql.functions import *\nsqlContext = SQLContext(sc)\n\n# @hidden_cell\n# This function is used to setup the access of Spark to your Object Storage. The definition contains your credentials.\n# You might want to remove those credentials before you share your notebook.\ndef set_hadoop_config_with_credentials_3a500b3a65a940508dadf71c13437e1d(name):\n    \"\"\"This function sets the Hadoop configuration so it is possible to\n    access data from Bluemix Object Storage using Spark\"\"\"\n\n    prefix = 'fs.swift.service.' + name\n    hconf = sc._jsc.hadoopConfiguration()\n    hconf.set(prefix + '.auth.url', 'https://identity.open.softlayer.com'+'/v3/auth/tokens')\n    hconf.set(prefix + '.auth.endpoint.prefix', 'endpoints')\n    hconf.set(prefix + '.tenant', '266ba3381db2401faf8aaa2af05a9146')\n    hconf.set(prefix + '.username', 'e6181ca8d25046b5a8f4ee43c04b79b8')\n    hconf.set(prefix + '.password', 'qK-mWT(9O,q89]cY')\n    hconf.setInt(prefix + '.http.port', 8080)\n    hconf.set(prefix + '.region', 'dallas')\n    hconf.setBoolean(prefix + '.public', False)\n\n# you can choose any name\nname = 'keystone'\nset_hadoop_config_with_credentials_3a500b3a65a940508dadf71c13437e1d(name)\n", "cell_type": "code", "outputs": []}, {"execution_count": 2, "metadata": {"collapsed": false}, "source": "tags_df = sqlContext.read.format('com.databricks.spark.csv')\\\n  .options(header='true', inferschema='true')\\\n  .load(\"swift://CS340.\" + name + \"/tags.csv\")", "cell_type": "code", "outputs": []}, {"execution_count": 3, "metadata": {"collapsed": false}, "source": "genome_tags_df = sqlContext.read.format('com.databricks.spark.csv')\\\n  .options(header='true', inferschema='true')\\\n  .load(\"swift://CS340.\" + name + \"/genome-tags.csv\")", "cell_type": "code", "outputs": []}, {"execution_count": 4, "metadata": {"collapsed": true}, "source": "genome_scores_df = sqlContext.read.format('com.databricks.spark.csv')\\\n  .options(header='true', inferschema='true')\\\n  .load(\"swift://CS340.\" + name + \"/genome-scores.csv\")", "cell_type": "code", "outputs": []}, {"execution_count": 5, "metadata": {"collapsed": true}, "source": "ratings_df = sqlContext.read.format('com.databricks.spark.csv')\\\n  .options(header='true', inferschema='true')\\\n  .load(\"swift://CS340.\" + name + \"/ratings.csv\")", "cell_type": "code", "outputs": []}, {"execution_count": 6, "metadata": {"collapsed": true}, "source": "movies_df = sqlContext.read.format('com.databricks.spark.csv')\\\n  .options(header='true', inferschema='true')\\\n  .load(\"swift://CS340.\" + name + \"/movies.csv\")", "cell_type": "code", "outputs": []}, {"execution_count": 7, "metadata": {"collapsed": false}, "source": "userid_movieid_tags = tags_df.select(\"userId\",\"movieId\",\"tag\")\n# userid_movieid_tags.show()", "cell_type": "code", "outputs": []}, {"execution_count": 8, "metadata": {"collapsed": false}, "source": "userid_movieid_tagId = userid_movieid_tags.join(genome_tags_df, genome_tags_df.tag == userid_movieid_tags.tag).select(\"userId\",\"movieId\",\"tagId\")\nuserid_movieid_tagId.show()", "cell_type": "code", "outputs": [{"name": "stdout", "output_type": "stream", "text": "+------+-------+-----+\n|userId|movieId|tagId|\n+------+-------+-----+\n| 70279|  68358|   29|\n| 70463|   2959|   29|\n| 70515|    480|   29|\n| 70592|  98809|   29|\n| 70592| 106489|   29|\n| 70833|    480|   29|\n| 70911|   7438|   29|\n| 71328|  34405|   29|\n| 71328|  77866|   29|\n| 71328|  78105|   29|\n| 71328|  79185|   29|\n| 71328| 106489|   29|\n| 71432|   1208|   29|\n| 71432|  48394|   29|\n| 71432|  77866|   29|\n| 71544|   2470|   29|\n| 71887|  76175|   29|\n| 71929|   1208|   29|\n| 71939|  77866|   29|\n| 71939|  85414|   29|\n+------+-------+-----+\nonly showing top 20 rows\n\n"}]}, {"execution_count": 9, "metadata": {"collapsed": false}, "source": "userId_reliability = userid_movieid_tagId.join(genome_scores_df, (userid_movieid_tagId.movieId == genome_scores_df.movieId)\\\n                                                           & (userid_movieid_tagId.tagId == genome_scores_df.tagId))\nuserId_reliability = userId_reliability.select(\"userId\", tanh(userId_reliability[\"relevance\"]*20 - 12))\nuserId_reliability = userId_reliability.groupBy(\"userId\").sum(userId_reliability.columns[-1])\nuserId_reliability = userId_reliability.select(col(userId_reliability.columns[0]).alias(\"userId\"), col(userId_reliability.columns[-1]).alias(\"reliability\"))\nuserId_reliability.show()", "cell_type": "code", "outputs": [{"name": "stdout", "output_type": "stream", "text": "+------+--------------------+\n|userId|         reliability|\n+------+--------------------+\n|  6431|   665.8821765083229|\n| 29831|   81.99768511072358|\n|106831|   2.340801667606085|\n|   631|   33.78900572273493|\n| 86231|  1.9999974957380933|\n|121631|  29.840888210409545|\n| 54431|  11.783470565361455|\n|117831|  5.2067628965686374|\n| 46431|   17.06159530430593|\n| 26831|    46.9825301538157|\n|111231|   81.11620036999845|\n| 16231|  37.999985848894546|\n| 47031| -0.9999006540637964|\n|  3031|   69.34044259878408|\n|124431|  1.0957575120283989|\n| 46231|   4.833363991053533|\n| 83631|  14.862813995762817|\n| 99431|  0.9999995557387478|\n|137031|-1.26206749930912...|\n|134031|  3.3841913131454553|\n+------+--------------------+\nonly showing top 20 rows\n\n"}]}, {"execution_count": 10, "metadata": {"collapsed": false}, "source": "top_thousand_users = userId_reliability.orderBy(col(\"reliability\").desc()).limit(1000)\n# assert top_thousand_users.count() == 1000\ntop_thousand_users.show()", "cell_type": "code", "outputs": [{"name": "stdout", "output_type": "stream", "text": "+------+------------------+\n|userId|       reliability|\n+------+------------------+\n| 88738| 5886.228605226696|\n| 58612|1700.3142105607255|\n| 52814| 1648.838228869247|\n| 11081|1582.5985838545291|\n| 10616|1447.9943988488747|\n|  9815|1413.2447981826167|\n| 68558|1261.1889719076667|\n|  1741|1119.2541784879347|\n| 25737|1068.4360438182064|\n|  4450|1000.3835964912713|\n| 27898| 969.4690500707222|\n|122523| 961.2716671956216|\n|119367| 959.6825546999676|\n| 77463| 927.4315434523476|\n|124998| 854.3481069572276|\n| 77297|  845.153160315068|\n| 28906| 840.9469449647927|\n|120937| 797.6761602947414|\n|  6431| 665.8821765083231|\n|111982| 662.9396577252996|\n+------+------------------+\nonly showing top 20 rows\n\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "##\u00a0Best Movies\n\n<br>\n<p style=\"text-indent: 40px\">For the second part of this assignment, we are going to get best 20 movies from those 1000 people's scores. For each movie in the ratings, you should multiply rating with the users score that we previously calculated and get the total of this score for each movie.\n\nIn the end we should be able to see the titles of the first 20 movies ranked by this criteria.\n</p>\n\n\n"}, {"execution_count": 11, "metadata": {"collapsed": false}, "source": "userId_movieId_rating_reliability = ratings_df.select(ratings_df.columns[:-1]).join(top_thousand_users, top_thousand_users.userId == ratings_df.userId)\\\n                                    .select(ratings_df.userId, \"movieId\",\"rating\",\"reliability\")\nuserId_movieId_rating_reliability.show()", "cell_type": "code", "outputs": [{"name": "stdout", "output_type": "stream", "text": "+------+-------+------+-----------------+\n|userId|movieId|rating|      reliability|\n+------+-------+------+-----------------+\n|    65|     24|   4.0|25.71999218707428|\n|    65|    318|   5.0|25.71999218707428|\n|    65|    356|   5.0|25.71999218707428|\n|    65|    364|   4.5|25.71999218707428|\n|    65|    443|   4.0|25.71999218707428|\n|    65|    480|   3.0|25.71999218707428|\n|    65|    541|   4.0|25.71999218707428|\n|    65|    588|   5.0|25.71999218707428|\n|    65|   1148|   3.5|25.71999218707428|\n|    65|   1197|   2.0|25.71999218707428|\n|    65|   1235|   5.0|25.71999218707428|\n|    65|   1250|   2.5|25.71999218707428|\n|    65|   1271|   4.5|25.71999218707428|\n|    65|   1348|   3.5|25.71999218707428|\n|    65|   1653|   4.0|25.71999218707428|\n|    65|   1688|   2.0|25.71999218707428|\n|    65|   1704|   3.5|25.71999218707428|\n|    65|   1801|   2.5|25.71999218707428|\n|    65|   1921|   3.5|25.71999218707428|\n|    65|   2114|   4.0|25.71999218707428|\n+------+-------+------+-----------------+\nonly showing top 20 rows\n\n"}]}, {"execution_count": 12, "metadata": {"collapsed": false}, "source": "movie_scores = userId_movieId_rating_reliability.withColumn(\"score\", userId_movieId_rating_reliability.rating * userId_movieId_rating_reliability.reliability)\\\n                .selectExpr(\"movieId as movieId1\",\"score as score\").groupBy(\"movieId1\").sum(\"score\")\ntop_20_movies = movie_scores.select(\"movieId1\",col(movie_scores.columns[-1]).alias(\"score\"))\\\n                .join(movies_df, movie_scores.movieId1 == movies_df.movieId).select(\"movieId\",\"title\",\"score\")\\\n    .orderBy(col(\"score\").desc()).limit(20)\ntop_20_movies.show()", "cell_type": "code", "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-------+--------------------+------------------+\n|movieId|               title|             score|\n+-------+--------------------+------------------+\n|   2571|  Matrix, The (1999)| 471354.5594368037|\n|   2959|   Fight Club (1999)| 426152.0577531985|\n|    296| Pulp Fiction (1994)|415367.08530751534|\n|    318|Shawshank Redempt...| 409525.1721352335|\n|    356| Forrest Gump (1994)|395281.52323548956|\n|   4993|Lord of the Rings...| 395052.4140476214|\n|   4226|      Memento (2000)|378664.83073142625|\n|  79132|    Inception (2010)| 375745.9660923454|\n|   5952|Lord of the Rings...|372978.42857394955|\n|   7153|Lord of the Rings...|364419.68578229175|\n|  58559|Dark Knight, The ...|361753.23284971487|\n|    593|Silence of the La...|360313.65050738555|\n|    260|Star Wars: Episod...|359782.00395323953|\n|   2858|American Beauty (...| 358955.4184849296|\n|   1270|Back to the Futur...|352814.61000777053|\n|   7361|Eternal Sunshine ...| 351084.1205756394|\n|   1196|Star Wars: Episod...| 349536.5973937372|\n|   2762|Sixth Sense, The ...|345048.85386349336|\n|     32|Twelve Monkeys (a...| 343691.1372185802|\n|     47|Seven (a.k.a. Se7...|340371.83759733755|\n+-------+--------------------+------------------+\n\n"}]}, {"execution_count": null, "metadata": {"collapsed": true}, "source": "", "cell_type": "code", "outputs": []}], "nbformat": 4}